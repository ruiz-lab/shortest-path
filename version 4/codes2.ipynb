{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from Graphs import matrix_to_graph, graph_to_matrix, ErdosRenyiGraph,dRegularGraph\n",
    "from ShortestDistanceAlgorithms import shortestDistance_allNodes_networkx, shortestDistance_allNodes_Bourgain, shortestDistance_allNodes_Sarma, onlineShortestPath_Bourgain, onlineShortestPath_Sarma\n",
    "from Models import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(gpu_bool,model,criterion_type,samples_x,samples_edge_index=[],samples_weights=[]):\n",
    "    \n",
    "    if len(samples_edge_index) > 0:\n",
    "        if len(samples_edge_index) == 1:\n",
    "            flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "    \n",
    "    y_pred = []\n",
    "    if gpu_bool:\n",
    "        model = model.to('cuda:1')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if model.out_channels == 1:\n",
    "            if model.name == 'mlp':\n",
    "                for x in samples_x:\n",
    "                    if gpu_bool:\n",
    "                        x = x.to('cuda:1')\n",
    "                    pred_all = []\n",
    "                    for j in range(x.shape[1]):\n",
    "                        out = model(x[:,j].reshape(len(x[:,j]),1))  # Perform a single forward pass.\n",
    "                        if criterion_type in ['bce','ce','multimargin']:\n",
    "                            pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                        elif criterion_type in ['mse','l2','l1']:\n",
    "                            pred = out.squeeze()\n",
    "                        else:\n",
    "                            pred = torch.round(out.squeeze())\n",
    "                        pred_all.append(pred.cpu())\n",
    "                    y_pred.append(np.array(pred_all).T)\n",
    "            elif len(samples_weights) == 0:\n",
    "                if flag:\n",
    "                    edge_index = samples_edge_index[-1]\n",
    "                    if gpu_bool:\n",
    "                        edge_index = edge_index.to('cuda:1')\n",
    "                    for x in samples_x:\n",
    "                        if gpu_bool:\n",
    "                            x = x.to('cuda:1')\n",
    "                        pred_all = []\n",
    "                        for j in range(x.shape[1]):\n",
    "                            out = model(x[:,j].reshape(len(x[:,j]),1),edge_index)  # Perform a single forward pass.\n",
    "                            if criterion_type in ['bce','ce','multimargin']:\n",
    "                                pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                            elif criterion_type in ['mse','l2','l1']:\n",
    "                                pred = out.squeeze()\n",
    "                            else:\n",
    "                                pred = torch.round(out.squeeze())\n",
    "                            pred_all.append(pred.cpu())\n",
    "                        y_pred.append(np.array(pred_all).T)\n",
    "                else:\n",
    "                    for x,edge_index in list(zip(samples_x,samples_edge_index)):\n",
    "                        if gpu_bool:\n",
    "                            x = x.to('cuda:1')\n",
    "                            edge_index = edge_index.to('cuda:1')\n",
    "                        pred_all = []\n",
    "                        for j in range(x.shape[1]):\n",
    "                            out = model(x[:,j].reshape(len(x[:,j]),1),edge_index)  # Perform a single forward pass.\n",
    "                            if criterion_type in ['bce','ce','multimargin']:\n",
    "                                pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                            elif criterion_type in ['mse','l2','l1']:\n",
    "                                pred = out.squeeze()\n",
    "                            else:\n",
    "                                pred = torch.round(out.squeeze())\n",
    "                            pred_all.append(pred.cpu())\n",
    "                        y_pred.append(np.array(pred_all).T)\n",
    "            else:\n",
    "                if flag:\n",
    "                    edge_index = samples_edge_index[-1]\n",
    "                    weights = samples_weights[-1]\n",
    "                    if gpu_bool:\n",
    "                        edge_index = edge_index.to('cuda:1')\n",
    "                        weights = weights.to('cuda:1')\n",
    "                    for x in samples_x:\n",
    "                        if gpu_bool:\n",
    "                            x = x.to('cuda:1')\n",
    "                        pred_all = []\n",
    "                        for j in range(x.shape[1]):\n",
    "                            out = model(x[:,j].reshape(len(x[:,j]),1),edge_index,weights)  # Perform a single forward pass.\n",
    "                            if criterion_type in ['bce','ce','multimargin']:\n",
    "                                pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                            elif criterion_type in ['mse','l2','l1']:\n",
    "                                pred = out.squeeze()\n",
    "                            else:\n",
    "                                pred = torch.round(out.squeeze())\n",
    "                            pred_all.append(pred.cpu())\n",
    "                        y_pred.append(np.array(pred_all).T)\n",
    "                else:\n",
    "                    for x,edge_index,weights in list(zip(samples_x,samples_edge_index,samples_weights)):\n",
    "                        if gpu_bool:\n",
    "                            x = x.to('cuda:1')\n",
    "                            edge_index = edge_index.to('cuda:1')\n",
    "                            weights = weights.to('cuda:1')\n",
    "                        pred_all = []\n",
    "                        for j in range(x.shape[1]):\n",
    "                            out = model(x[:,j].reshape(len(x[:,j]),1),edge_index,weights)  # Perform a single forward pass.\n",
    "                            if criterion_type in ['bce','ce','multimargin']:\n",
    "                                pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                            elif criterion_type in ['mse','l2','l1']:\n",
    "                                pred = out.squeeze()\n",
    "                            else:\n",
    "                                pred = torch.round(out.squeeze())\n",
    "                            pred_all.append(pred.cpu())\n",
    "                        y_pred.append(np.array(pred_all).T)\n",
    "        else:\n",
    "            if model.name == 'mlp':\n",
    "                for x in samples_x:\n",
    "                    if gpu_bool:\n",
    "                        x = x.to('cuda:1')\n",
    "                    out = model(x)  # Perform a single forward pass.\n",
    "                    if criterion_type in ['bce','ce','multimargin']:\n",
    "                        pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                    elif criterion_type in ['mse','l2','l1']:\n",
    "                        pred = out.squeeze()\n",
    "                    else:\n",
    "                        pred = torch.round(out.squeeze())\n",
    "                    y_pred.append(pred.cpu())\n",
    "            elif len(samples_weights) == 0:\n",
    "                if flag:\n",
    "                    edge_index = samples_edge_index[-1]\n",
    "                    if gpu_bool:\n",
    "                        edge_index = edge_index.to('cuda:1')\n",
    "                    for x in samples_x:\n",
    "                        if gpu_bool:\n",
    "                            x = x.to('cuda:1')\n",
    "                        out = model(x,edge_index)  # Perform a single forward pass.\n",
    "                        if criterion_type in ['bce','ce','multimargin']:\n",
    "                            pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                        elif criterion_type in ['mse','l2','l1']:\n",
    "                            pred = out.squeeze()\n",
    "                        else:\n",
    "                            pred = torch.round(out.squeeze())\n",
    "                        y_pred.append(pred.cpu())\n",
    "                else:\n",
    "                    for x,edge_index in list(zip(samples_x,samples_edge_index)):\n",
    "                        if gpu_bool:\n",
    "                            x = x.to('cuda:1')\n",
    "                            edge_index = edge_index.to('cuda:1')\n",
    "                        out = model(x,edge_index)  # Perform a single forward pass.\n",
    "                        if criterion_type in ['bce','ce','multimargin']:\n",
    "                            pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                        elif criterion_type in ['mse','l2','l1']:\n",
    "                            pred = out.squeeze()\n",
    "                        else:\n",
    "                            pred = torch.round(out.squeeze())\n",
    "                        y_pred.append(pred.cpu())\n",
    "            else:\n",
    "                if flag:\n",
    "                    edge_index = samples_edge_index[-1]\n",
    "                    weights = samples_weights[-1]\n",
    "                    if gpu_bool:\n",
    "                        edge_index = edge_index.to('cuda:1')\n",
    "                        weights = weights.to('cuda:1')\n",
    "                    for x in samples_x:\n",
    "                        if gpu_bool:\n",
    "                            x = x.to('cuda:1')\n",
    "                        out = model(x,edge_index,weights)  # Perform a single forward pass.\n",
    "                        if criterion_type in ['bce','ce','multimargin']:\n",
    "                            pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                        elif criterion_type in ['mse','l2','l1']:\n",
    "                            pred = out.squeeze()\n",
    "                        else:\n",
    "                            pred = torch.round(out.squeeze())\n",
    "                        y_pred.append(pred.cpu())\n",
    "                else:\n",
    "                    for x,edge_index,weights in list(zip(samples_x,samples_edge_index,samples_weights)):\n",
    "                        if gpu_bool:\n",
    "                            x = x.to('cuda:1')\n",
    "                            edge_index = edge_index.to('cuda:1')\n",
    "                            weights = weights.to('cuda:1')\n",
    "                        out = model(x,edge_index,weights)  # Perform a single forward pass.\n",
    "                        if criterion_type in ['bce','ce','multimargin']:\n",
    "                            pred = out.argmax(dim=1) #  Use the class with highest probability.\n",
    "                        elif criterion_type in ['mse','l2','l1']:\n",
    "                            pred = out.squeeze()\n",
    "                        else:\n",
    "                            pred = torch.round(out.squeeze())\n",
    "                        y_pred.append(pred.cpu())\n",
    "    model = model.to('cpu')\n",
    "    return y_pred\n",
    "\n",
    "def predict_allBatches(model,criterion_type,samples):\n",
    "    gpu_bool = torch.cuda.is_available()\n",
    "    y_pred_train = predict(gpu_bool, model, criterion_type, samples[0][0], samples[0][2], samples[0][3])\n",
    "    y_pred_val = predict(gpu_bool, model, criterion_type, samples[1][0], samples[1][2], samples[1][3])\n",
    "    y_pred_test = predict(gpu_bool, model, criterion_type, samples[2][0], samples[2][2], samples[2][3])\n",
    "    return y_pred_train,y_pred_val,y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offlineSample_GNN(model,criterion_type,G,u,samples_edge_index,samples_weights):\n",
    "\n",
    "    n_nodes = len(G.nodes())\n",
    "    if n_nodes <= 1:\n",
    "        return None, set()\n",
    "    r = int(np.floor(np.log(n_nodes)))\n",
    "    sample_sets = [np.random.choice(G.nodes(),size=2**i,replace=False) for i in range(r+1)]\n",
    "\n",
    "    gpu_bool = torch.cuda.is_available()\n",
    "    out = model.out_channels\n",
    "    x = np.zeros((n_nodes,out))\n",
    "    x[u,0] = 1\n",
    "    if out > 1:\n",
    "        extra_seeds = np.random.choice(G.nodes(),size=out-1,replace=True)\n",
    "        for i in range(out-1):\n",
    "            x[extra_seeds[i],i+1] = 1\n",
    "    samples_x = [torch.tensor(x.astype(np.float32), requires_grad=True)]\n",
    "    y_pred = predict(gpu_bool, model, criterion_type, samples_x, samples_edge_index, samples_weights)[0][:,0]\n",
    "    distances = [[y_pred[i] for i in S] for S in sample_sets]\n",
    "    index = [d.index(min(d)) for d in distances]\n",
    "    closest_points = set([(sample_sets[i][index[i]],distances[i][index[i]]) for i in range(r+1)])\n",
    "    return closest_points,set(np.concatenate(sample_sets))\n",
    "\n",
    "def offlineSketch_GNN(model,criterion_type,G,u,k,samples_edge_index,samples_weights):\n",
    "    closest_points,sample_sets = offlineSample_GNN(model,criterion_type,G,u,samples_edge_index,samples_weights)\n",
    "    for i in range(k):\n",
    "        closest_points_new,sample_sets_new = offlineSample_GNN(model,criterion_type,G,u,samples_edge_index,samples_weights)\n",
    "        closest_points = closest_points.union(closest_points_new)\n",
    "        sample_sets = sample_sets.union(sample_sets_new)\n",
    "    #print(np.array(list(closest_points)).shape[0])\n",
    "    return np.array(list(closest_points)),np.array(list(sample_sets))\n",
    "\n",
    "def onlineShortestPath_Sarma_GNN(model1,model2,criterion_type,G,u,v,k,samples_edge_index,samples_weights): ## upper bound\n",
    "    ## if undirected, model1 = model2\n",
    "    ## else, model1 calculates distances from u to each k and model2 calculates distances from eack k to v\n",
    "    sketch_u,_ = offlineSketch_GNN(model1,criterion_type,G,u,k,samples_edge_index,samples_weights)\n",
    "    sketch_v,_ = offlineSketch_GNN(model2,criterion_type,G,v,k,samples_edge_index,samples_weights)\n",
    "    if sketch_u.shape[0] != 0 and sketch_v.shape[0] != 0:\n",
    "        common_nodes = [w for w in sketch_u[:,0] if w in sketch_v[:,0]]\n",
    "        while None in common_nodes:\n",
    "            common_nodes.remove(None)\n",
    "        min_dist = float('inf')\n",
    "        for w in common_nodes:\n",
    "            dist = sketch_u[sketch_u[:, 0] == w][0,1] + sketch_v[sketch_v[:, 0] == w][0,1]\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "        return min_dist\n",
    "    else:\n",
    "        return float('inf')\n",
    "\n",
    "def onlineShortestPath_Bourgain_GNN(model1,model2,criterion_type,G,u,v,samples_edge_index,samples_weights): ## lower bound\n",
    "\n",
    "    n_nodes = len(G.nodes())\n",
    "    if n_nodes <= 1:\n",
    "        return None, set()\n",
    "    r = int(np.floor(np.log(n_nodes)))\n",
    "    sample_sets = [np.random.choice(G.nodes(),size=2**i,replace=False) for i in range(r+1)]\n",
    "\n",
    "    gpu_bool = torch.cuda.is_available()\n",
    "    if model1 == model2: # set model1 = model2 if undirected, model used need to be trained on undirected graphs\n",
    "        out = model1.out_channels\n",
    "        x = np.zeros((n_nodes,out))\n",
    "        x[u,0] = 1\n",
    "        if out > 1:\n",
    "            x[v,1] = 1\n",
    "            extra_seeds = np.random.choice(G.nodes(),size=out-2,replace=True)\n",
    "            for i in range(out-2):\n",
    "                x[extra_seeds[i],i+2] = 1\n",
    "            samples_x = [torch.tensor(x.astype(np.float32), requires_grad=True)]\n",
    "            y_pred = predict(gpu_bool, model1, criterion_type, samples_x, samples_edge_index, samples_weights)[0]\n",
    "            y_pred_u = y_pred[:,0]\n",
    "            y_pred_v = y_pred[:,1]\n",
    "        if out == 1:\n",
    "            samples_x = [torch.tensor(x.astype(np.float32), requires_grad=True)]\n",
    "            y_pred_u = predict(gpu_bool, model1, criterion_type, samples_x, samples_edge_index, samples_weights)[0][:,0]\n",
    "            x = np.zeros((n_nodes,out))\n",
    "            x[v,0] = 1\n",
    "            samples_x = [torch.tensor(x.astype(np.float32), requires_grad=True)]\n",
    "            y_pred_v = predict(gpu_bool, model1, criterion_type, samples_x, samples_edge_index, samples_weights)[0][:,0]\n",
    "        d_u_S = np.array([min([y_pred_u[i] for i in S]) for S in sample_sets])\n",
    "        d_v_S = np.array([min([y_pred_v[i] for i in S]) for S in sample_sets])\n",
    "        return np.max(np.abs(d_u_S-d_v_S))\n",
    "    else:\n",
    "        out = model1.out_channels\n",
    "        x = np.zeros((n_nodes,out))\n",
    "        x[u,0] = 1\n",
    "        if out > 1:\n",
    "            extra_seeds = np.random.choice(G.nodes(),size=out-1,replace=True)\n",
    "            for i in range(out-1):\n",
    "                x[extra_seeds[i],i+1] = 1\n",
    "        samples_x = [torch.tensor(x.astype(np.float32), requires_grad=True)]\n",
    "        y_pred_u_k = predict(gpu_bool, model1, criterion_type, samples_x, samples_edge_index, samples_weights)[0][:,0]\n",
    "        x = np.zeros((n_nodes,out))\n",
    "        x[v,0] = 1\n",
    "        if out > 1:\n",
    "            extra_seeds = np.random.choice(G.nodes(),size=out-1,replace=True)\n",
    "            for i in range(out-1):\n",
    "                x[extra_seeds[i],i+1] = 1\n",
    "        samples_x = [torch.tensor(x.astype(np.float32), requires_grad=True)]\n",
    "        y_pred_v_k = predict(gpu_bool, model1, criterion_type, samples_x, samples_edge_index, samples_weights)[0][:,0]\n",
    "        out = model2.out_channels\n",
    "        x = np.zeros((n_nodes,out))\n",
    "        x[u,0] = 1\n",
    "        if out > 1:\n",
    "            extra_seeds = np.random.choice(G.nodes(),size=out-1,replace=True)\n",
    "            for i in range(out-1):\n",
    "                x[extra_seeds[i],i+1] = 1\n",
    "        samples_x = [torch.tensor(x.astype(np.float32), requires_grad=True)]\n",
    "        y_pred_k_u = predict(gpu_bool, model2, criterion_type, samples_x, samples_edge_index, samples_weights)[0][:,0]\n",
    "        x = np.zeros((n_nodes,out))\n",
    "        x[v,0] = 1\n",
    "        if out > 1:\n",
    "            extra_seeds = np.random.choice(G.nodes(),size=out-1,replace=True)\n",
    "            for i in range(out-1):\n",
    "                x[extra_seeds[i],i+1] = 1\n",
    "        samples_x = [torch.tensor(x.astype(np.float32), requires_grad=True)]\n",
    "        y_pred_k_v = predict(gpu_bool, model2, criterion_type, samples_x, samples_edge_index, samples_weights)[0][:,0]\n",
    "        d_u_S = np.array([min([y_pred_u_k[i] for i in S]) for S in sample_sets])\n",
    "        d_v_S = np.array([min([y_pred_v_k[i] for i in S]) for S in sample_sets])\n",
    "        d_S_u = np.array([min([y_pred_k_u[i] for i in S]) for S in sample_sets])\n",
    "        d_S_v = np.array([min([y_pred_k_v[i] for i in S]) for S in sample_sets])\n",
    "        return max([0,np.max(d_S_v-d_S_u),np.max(d_u_S-d_v_S)])\n",
    "\n",
    "def shortestDistance_allNodes_Sarma_GNN(model1,model2,criterion_type,G,u,k,samples_edge_index,samples_weights):\n",
    "    ## if undirected, model1 = model2\n",
    "    ## else, model1 calculates distances from u to each k and model2 calculates distances from eack k to v\n",
    "    distances = np.zeros(len(G.nodes()))\n",
    "    for v in range(len(G.nodes())):\n",
    "        if u != v:\n",
    "            distances[v] = onlineShortestPath_Sarma_GNN(model1,model2,criterion_type,G,u,v,k,samples_edge_index,samples_weights)\n",
    "    return distances\n",
    "\n",
    "def shortestDistance_allNodes_Bourgain_GNN(model1,model2,criterion_type,G,u,samples_edge_index,samples_weights):\n",
    "    ## if undirected, model1 = model2\n",
    "    ## else, model1 calculates distances from u to each k and model2 calculates distances from eack k to v\n",
    "    distances = np.zeros(len(G.nodes()))\n",
    "    for v in range(len(G.nodes())):\n",
    "        if u != v:\n",
    "            distances[v] = onlineShortestPath_Bourgain_GNN(model1,model2,criterion_type,G,u,v,samples_edge_index,samples_weights)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGraphs(num_graphs,function,*args,**kwargs):\n",
    "    graphs = []\n",
    "    is_directed =[]\n",
    "    is_weighted = []\n",
    "    graph_sizes = []\n",
    "    k = 0\n",
    "    n_rejected1 = 0\n",
    "    n_rejected2 = 0\n",
    "    while k < num_graphs:\n",
    "        try:\n",
    "            object,directed,weighted = function(*args,**kwargs)\n",
    "            n = len(object.nodes())\n",
    "            components = list(nx.strongly_connected_components(object))\n",
    "            largest_component = max(components, key=len)\n",
    "            n_nodes = len(largest_component)\n",
    "            r = int(np.floor(np.sqrt(n)))\n",
    "            if n_nodes >= max(r,10):\n",
    "                object = object.subgraph(largest_component)\n",
    "                object = nx.relabel_nodes(object, {node: index for index, node in enumerate(object.nodes())})\n",
    "                graphs.append(object)\n",
    "                is_directed.append(directed)\n",
    "                is_weighted.append(weighted)\n",
    "                graph_sizes.append(n_nodes)\n",
    "                k += 1\n",
    "            else:\n",
    "                n_rejected2 += 1\n",
    "        except:\n",
    "            n_rejected1 += 1\n",
    "    print('Number of graphs rejected because Bourgain\\'s and Sarma\\'s algorithms yield errors: ',n_rejected1)\n",
    "    print('Number of graphs rejected because the largest component has insufficient size: ',n_rejected2)\n",
    "    return graphs,is_directed,is_weighted,min(graph_sizes)\n",
    "\n",
    "def estimate_AllShortestDistances(graph_data,model1,model2,criterion_type,calculate_Bourgain_Sarma = True,print_summary=False):\n",
    "    \n",
    "    graphs = graph_data[0]\n",
    "    is_directed = graph_data[1]\n",
    "    is_weighted = graph_data[2]\n",
    "\n",
    "    dur = np.zeros((9,len(graphs)))\n",
    "    mse = np.zeros((9,len(graphs)))\n",
    "\n",
    "    for i in range(len(graphs)):\n",
    "\n",
    "        #print(i)\n",
    "\n",
    "        G = graphs[i]\n",
    "        directed = is_directed[i]\n",
    "        weighted = is_weighted[i]\n",
    "\n",
    "        samples_edge_index = [torch.tensor(np.array(list(G.edges())).T).to(torch.int64)]\n",
    "        if weighted:\n",
    "            samples_weights = [torch.tensor(list(nx.get_edge_attributes(G,'weight').values())).to(torch.float32)]\n",
    "        else:\n",
    "            samples_weights = []\n",
    "\n",
    "        matrix = graph_to_matrix(G)\n",
    "        n_nodes = matrix.shape[0]\n",
    "        M = n_nodes\n",
    "\n",
    "        if directed:\n",
    "    \n",
    "            start_time = time.time()\n",
    "            y_actual = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                y_actual[:,u] = shortestDistance_allNodes_networkx(G,u,weight='weight')\n",
    "            end_time = time.time()\n",
    "            dur[0,i] = end_time - start_time\n",
    "\n",
    "            if calculate_Bourgain_Sarma:\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_Bourgain = np.zeros((n_nodes,n_nodes))\n",
    "                for u in range(n_nodes):\n",
    "                    y_Bourgain[:,u] = shortestDistance_allNodes_Bourgain(matrix,u,directed)\n",
    "                y_Bourgain = np.where(y_Bourgain == float('inf'), M, y_Bourgain)\n",
    "                end_time = time.time()\n",
    "                dur[1,i] = end_time - start_time\n",
    "                mse[1,i] = mean_squared_error(y_actual, y_Bourgain)\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_Sarma1 = np.zeros((n_nodes,n_nodes))\n",
    "                for u in range(n_nodes):\n",
    "                    y_Sarma1[:,u] = shortestDistance_allNodes_Sarma(matrix,u,1,directed)\n",
    "                y_Sarma1 = np.where(y_Sarma1 == float('inf'), M, y_Sarma1)\n",
    "                end_time = time.time()\n",
    "                dur[2,i] = end_time - start_time\n",
    "                mse[2,i] = mean_squared_error(y_actual, y_Sarma1)\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_Sarma2 = np.zeros((n_nodes,n_nodes))\n",
    "                for u in range(n_nodes):\n",
    "                    y_Sarma2[:,u] = shortestDistance_allNodes_Sarma(matrix,u,2,directed)\n",
    "                y_Sarma2 = np.where(y_Sarma2 == float('inf'), M, y_Sarma2)\n",
    "                end_time = time.time()\n",
    "                dur[3,i] = end_time - start_time\n",
    "                mse[3,i] = mean_squared_error(y_actual, y_Sarma2)\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_Sarma3 = np.zeros((n_nodes,n_nodes))\n",
    "                for u in range(n_nodes):\n",
    "                    y_Sarma3[:,u] = shortestDistance_allNodes_Sarma(matrix,u,3,directed)\n",
    "                y_Sarma3 = np.where(y_Sarma3 == float('inf'), M, y_Sarma3)\n",
    "                end_time = time.time()\n",
    "                dur[4,i] = end_time - start_time\n",
    "                mse[4,i] = mean_squared_error(y_actual, y_Sarma3)\n",
    "\n",
    "            start_time = time.time()\n",
    "            y_Bourgain_GNN = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                #print(u)\n",
    "                y_Bourgain_GNN[:,u] = shortestDistance_allNodes_Bourgain_GNN(model1,model2,criterion_type,G,u,samples_edge_index,samples_weights)\n",
    "            y_Bourgain_GNN = np.where(y_Bourgain_GNN == float('inf'), M, y_Bourgain_GNN)\n",
    "            end_time = time.time()\n",
    "            dur[5,i] = end_time - start_time\n",
    "            mse[5,i] = mean_squared_error(y_actual, y_Bourgain_GNN)\n",
    "\n",
    "            start_time = time.time()\n",
    "            y_Sarma1_GNN = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                y_Sarma1_GNN[:,u] = shortestDistance_allNodes_Sarma_GNN(model1,model2,criterion_type,G,u,1,samples_edge_index,samples_weights)\n",
    "            y_Sarma1_GNN = np.where(y_Sarma1_GNN == float('inf'), M, y_Sarma1_GNN)\n",
    "            end_time = time.time()\n",
    "            dur[6,i] = end_time - start_time\n",
    "            mse[6,i] = mean_squared_error(y_actual, y_Sarma1_GNN)\n",
    "\n",
    "            start_time = time.time()\n",
    "            y_Sarma2_GNN = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                y_Sarma2_GNN[:,u] = shortestDistance_allNodes_Sarma_GNN(model1,model2,criterion_type,G,u,2,samples_edge_index,samples_weights)\n",
    "            y_Sarma2_GNN = np.where(y_Sarma2_GNN == float('inf'), M, y_Sarma2_GNN)\n",
    "            end_time = time.time()\n",
    "            dur[7,i] = end_time - start_time\n",
    "            mse[7,i] = mean_squared_error(y_actual, y_Sarma2_GNN)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            y_Sarma3_GNN = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                y_Sarma3_GNN[:,u] = shortestDistance_allNodes_Sarma_GNN(model1,model2,criterion_type,G,u,3,samples_edge_index,samples_weights)\n",
    "            y_Sarma3_GNN = np.where(y_Sarma3_GNN == float('inf'), M, y_Sarma3_GNN)\n",
    "            end_time = time.time()\n",
    "            dur[8,i] = end_time - start_time\n",
    "            mse[8,i] = mean_squared_error(y_actual, y_Sarma3_GNN)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            start_time = time.time()\n",
    "            y_actual = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                for v in range(i+1,n_nodes):\n",
    "                    y_actual[v,u] = nx.shortest_path_length(G, u, v, weight='weight')\n",
    "                    y_actual[u,v] = y_actual[v,i]\n",
    "            end_time = time.time()\n",
    "            dur[0,i] = end_time - start_time\n",
    "\n",
    "            if calculate_Bourgain_Sarma:\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_Bourgain = np.zeros((n_nodes,n_nodes))\n",
    "                for u in range(n_nodes):\n",
    "                    for v in range(i+1,n_nodes):\n",
    "                        y_Bourgain[v,u] = onlineShortestPath_Bourgain(matrix,u,v,directed)\n",
    "                        y_Bourgain[u,v] = y_Bourgain[v,u]\n",
    "                y_Bourgain = np.where(y_Bourgain == float('inf'), M, y_Bourgain)\n",
    "                end_time = time.time()\n",
    "                dur[1,i] = end_time - start_time\n",
    "                mse[1,i] = mean_squared_error(y_actual, y_Bourgain)\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_Sarma1 = np.zeros((n_nodes,n_nodes))\n",
    "                for u in range(n_nodes):\n",
    "                    for v in range(i+1,n_nodes):\n",
    "                        y_Sarma1[v,u] = onlineShortestPath_Sarma(matrix,u,v,1,directed)\n",
    "                        y_Sarma1[u,v] = y_Sarma1[v,u]\n",
    "                y_Sarma1 = np.where(y_Sarma1 == float('inf'), M, y_Sarma1)\n",
    "                end_time = time.time()\n",
    "                dur[2,i] = end_time - start_time\n",
    "                mse[2,i] = mean_squared_error(y_actual, y_Sarma1)\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_Sarma2 = np.zeros((n_nodes,n_nodes))\n",
    "                for u in range(n_nodes):\n",
    "                    for v in range(i+1,n_nodes):\n",
    "                        y_Sarma2[v,u] = onlineShortestPath_Sarma(matrix,u,v,2,directed)\n",
    "                        y_Sarma2[u,v] = y_Sarma2[v,u]\n",
    "                y_Sarma2 = np.where(y_Sarma2 == float('inf'), M, y_Sarma2)\n",
    "                end_time = time.time()\n",
    "                dur[3,i] = end_time - start_time\n",
    "                mse[3,i] = mean_squared_error(y_actual, y_Sarma2)\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_Sarma3 = np.zeros((n_nodes,n_nodes))\n",
    "                for u in range(n_nodes):\n",
    "                    for v in range(i+1,n_nodes):\n",
    "                        y_Sarma3[v,u] = onlineShortestPath_Sarma(matrix,u,v,3,directed)\n",
    "                        y_Sarma3[u,v] = y_Sarma3[v,u]\n",
    "                y_Sarma3 = np.where(y_Sarma3 == float('inf'), M, y_Sarma3)\n",
    "                end_time = time.time()\n",
    "                dur[4,i] = end_time - start_time\n",
    "                mse[4,i] = mean_squared_error(y_actual, y_Sarma3)\n",
    "\n",
    "            start_time = time.time()\n",
    "            y_Bourgain_GNN = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                for v in range(i+1,n_nodes):\n",
    "                    y_Bourgain_GNN[v,u] = onlineShortestPath_Bourgain_GNN(model1,model2,criterion_type,G,u,v,samples_edge_index,samples_weights)\n",
    "                    y_Bourgain_GNN[u,v] = y_Bourgain_GNN[v,u]\n",
    "            y_Bourgain_GNN = np.where(y_Bourgain_GNN == float('inf'), M, y_Bourgain_GNN)\n",
    "            end_time = time.time()\n",
    "            dur[5,i] = end_time - start_time\n",
    "            mse[5,i] = mean_squared_error(y_actual, y_Bourgain_GNN)\n",
    "\n",
    "            start_time = time.time()\n",
    "            y_Sarma1_GNN = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                for v in range(i+1,n_nodes):\n",
    "                    y_Sarma1_GNN[v,u] = onlineShortestPath_Sarma_GNN(model1,model2,criterion_type,G,u,v,1,samples_edge_index,samples_weights)\n",
    "                    y_Sarma1_GNN[u,v] = y_Sarma1_GNN[v,u]\n",
    "            y_Sarma1_GNN = np.where(y_Sarma1_GNN == float('inf'), M, y_Sarma1_GNN)\n",
    "            end_time = time.time()\n",
    "            dur[6,i] = end_time - start_time\n",
    "            mse[6,i] = mean_squared_error(y_actual, y_Sarma1_GNN)\n",
    "\n",
    "            start_time = time.time()\n",
    "            y_Sarma2_GNN = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                for v in range(i+1,n_nodes):\n",
    "                    y_Sarma2_GNN[v,u] = onlineShortestPath_Sarma_GNN(model1,model2,criterion_type,G,u,v,2,samples_edge_index,samples_weights)\n",
    "                    y_Sarma2_GNN[u,v] = y_Sarma2_GNN[v,u]\n",
    "            y_Sarma2_GNN = np.where(y_Sarma2_GNN == float('inf'), M, y_Sarma2_GNN)\n",
    "            end_time = time.time()\n",
    "            dur[7,i] = end_time - start_time\n",
    "            mse[7,i] = mean_squared_error(y_actual, y_Sarma2_GNN)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            y_Sarma3_GNN = np.zeros((n_nodes,n_nodes))\n",
    "            for u in range(n_nodes):\n",
    "                for v in range(i+1,n_nodes):\n",
    "                    y_Sarma3_GNN[v,u] = onlineShortestPath_Sarma_GNN(model1,model2,criterion_type,G,u,v,3,samples_edge_index,samples_weights)\n",
    "                    y_Sarma3_GNN[u,v] = y_Sarma3_GNN[v,u]\n",
    "            y_Sarma3_GNN = np.where(y_Sarma3_GNN == float('inf'), M, y_Sarma3_GNN)\n",
    "            end_time = time.time()\n",
    "            dur[8,i] = end_time - start_time\n",
    "            mse[8,i] = mean_squared_error(y_actual, y_Sarma3_GNN)\n",
    "        \n",
    "    mse_mean = np.mean(mse, axis=1)\n",
    "    dur_mean = np.mean(dur, axis=1)\n",
    "    \n",
    "    if print_summary:\n",
    "        print('networkx: MSE = '+str(mse_mean[0])+', runtime = '+str(dur_mean[0])+' seconds')\n",
    "        print('Bourgain: MSE = '+str(mse_mean[1])+', runtime = '+str(dur_mean[1])+' seconds')\n",
    "        print('Sarma, k = 1: MSE = '+str(mse_mean[2])+', runtime = '+str(dur_mean[2])+' seconds')\n",
    "        print('Sarma, k = 2: MSE = '+str(mse_mean[3])+', runtime = '+str(dur_mean[3])+' seconds')\n",
    "        print('Sarma, k = 3: MSE = '+str(mse_mean[4])+', runtime = '+str(dur_mean[4])+' seconds')\n",
    "        print('Bourgain-GNN: MSE = '+str(mse_mean[5])+', runtime = '+str(dur_mean[5])+' seconds')\n",
    "        print('Sarma-GNN, k = 1: MSE = '+str(mse_mean[6])+', runtime = '+str(dur_mean[6])+' seconds')\n",
    "        print('Sarma-GNN, k = 2: MSE = '+str(mse_mean[7])+', runtime = '+str(dur_mean[7])+' seconds')\n",
    "        print('Sarma-GNN, k = 3: MSE = '+str(mse_mean[8])+', runtime = '+str(dur_mean[8])+' seconds')\n",
    "\n",
    "    return mse_mean, dur_mean\n",
    "\n",
    "def evaluate_all_algs(model_dir,num_graphs,function,*args,**kwargs):\n",
    "    all_out_channels = [int(item[9:-4]) for item in os.listdir(model_dir) if item.startswith('model_out')]\n",
    "    r = int(np.floor(np.sqrt(n)))\n",
    "    graph_data = generateGraphs(num_graphs,function,*args,**kwargs)\n",
    "    print('Min graph size: '+str(graph_data[3]))\n",
    "    if r not in all_out_channels:\n",
    "        out_selected = [out for out in all_out_channels if out <= graph_data[3]]\n",
    "        if len(out_selected) > 0:\n",
    "            r = max(out_selected)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Model not available.'\n",
    "            )\n",
    "    model_outr,_,_,_ = build(r, r, 'gcn','mse','adam','cyclic-cosine')\n",
    "    model_outr.load_state_dict(torch.load(model_dir+'/model_out'+str(r)+'.pth'))\n",
    "    print('GNN with out_channels = '+str(r))\n",
    "    mse1,dur1 = estimate_AllShortestDistances(graph_data,model_outr,model_outr,'mse',True)\n",
    "    if r != 1:\n",
    "        model_out1,_,_,_ = build(1, 1, 'gcn','mse','adam','cyclic-cosine')\n",
    "        model_out1.load_state_dict(torch.load(model_dir+'/model_out1.pth'))\n",
    "        print('GNN with out_channels = 1')\n",
    "        mse2,dur2 = estimate_AllShortestDistances(graph_data,model_out1,model_out1,'mse',True)\n",
    "    return [mse1,mse2],[dur1,dur2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'outputs2'\n",
    "num_graphs = 100\n",
    "graph_sizes = list(np.array(range(1,10))*10)+list(2**np.array(range(9))*100)\n",
    "lbds = [2,4,6]\n",
    "\n",
    "if os.path.exists(model_dir+'/results.pkl'):\n",
    "    with open(model_dir+'/results.pkl', 'rb') as file:\n",
    "        results = pickle.load(file)\n",
    "else:\n",
    "    results = []\n",
    "\n",
    "for n in graph_sizes:\n",
    "    for lbd in lbds:\n",
    "        mse,dur = evaluate_all_algs(model_dir,num_graphs,dRegularGraph,n,lbd)\n",
    "        results.append([[n,lbd,num_graphs],mse,dur])\n",
    "        with open(model_dir+'/results.pkl', 'wb') as file:\n",
    "            pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs rejected because Bourgain's and Sarma's algorithms yield errors:  0\n",
      "Number of graphs rejected because the largest component has insufficient size:  0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "(array([  0.28226895,  20.64235311,  42.62032714,  63.75388665,\n",
      "        84.7655674 ,  17.52850881,  68.36310229, 102.47579651,\n",
      "       136.47396355]), array([   0.        ,   20.87908171, 2186.5779133 ,  884.75924051,\n",
      "        304.30625398,   80.13021451, 2110.94547699,  678.47364176,\n",
      "        169.09748665]))\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m model_out1,_,_,_ \u001b[38;5;241m=\u001b[39m build(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgcn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcyclic-cosine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m model_out1\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs1/model_out\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mestimate_AllShortestDistances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_out1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_out1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcalculate_Bourgain_Sarma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[5], line 111\u001b[0m, in \u001b[0;36mestimate_AllShortestDistances\u001b[0;34m(graph_data, model1, model2, criterion_type, calculate_Bourgain_Sarma)\u001b[0m\n\u001b[1;32m    109\u001b[0m y_Sarma1_GNN \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_nodes,n_nodes))\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_nodes):\n\u001b[0;32m--> 111\u001b[0m     y_Sarma1_GNN[:,u] \u001b[38;5;241m=\u001b[39m \u001b[43mshortestDistance_allNodes_Sarma_GNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m y_Sarma1_GNN \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_Sarma1_GNN \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), M, y_Sarma1_GNN)\n\u001b[1;32m    113\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[4], line 140\u001b[0m, in \u001b[0;36mshortestDistance_allNodes_Sarma_GNN\u001b[0;34m(model1, model2, criterion_type, G, u, k, weighted)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(G\u001b[38;5;241m.\u001b[39mnodes())):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m u \u001b[38;5;241m!=\u001b[39m v:\n\u001b[0;32m--> 140\u001b[0m         distances[v] \u001b[38;5;241m=\u001b[39m \u001b[43monlineShortestPath_Sarma_GNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m distances\n",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m, in \u001b[0;36monlineShortestPath_Sarma_GNN\u001b[0;34m(model1, model2, criterion_type, G, u, v, k, weighted)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21monlineShortestPath_Sarma_GNN\u001b[39m(model1,model2,criterion_type,G,u,v,k,weighted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \u001b[38;5;66;03m## upper bound\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m## if undirected, model1 = model2\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m## else, model1 calculates distances from u to each k and model2 calculates distances from eack k to v\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     sketch_u,_ \u001b[38;5;241m=\u001b[39m offlineSketch_GNN(model1,criterion_type,G,u,k,weighted)\n\u001b[0;32m---> 42\u001b[0m     sketch_v,_ \u001b[38;5;241m=\u001b[39m \u001b[43mofflineSketch_GNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sketch_u\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sketch_v\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     44\u001b[0m         common_nodes \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m sketch_u[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m sketch_v[:,\u001b[38;5;241m0\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mofflineSketch_GNN\u001b[0;34m(model, criterion_type, G, u, k, weighted)\u001b[0m\n\u001b[1;32m     30\u001b[0m closest_points,sample_sets \u001b[38;5;241m=\u001b[39m offlineSample_GNN(model,criterion_type,G,u,weighted)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[0;32m---> 32\u001b[0m     closest_points_new,sample_sets_new \u001b[38;5;241m=\u001b[39m \u001b[43mofflineSample_GNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     closest_points \u001b[38;5;241m=\u001b[39m closest_points\u001b[38;5;241m.\u001b[39munion(closest_points_new)\n\u001b[1;32m     34\u001b[0m     sample_sets \u001b[38;5;241m=\u001b[39m sample_sets\u001b[38;5;241m.\u001b[39munion(sample_sets_new)\n",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m, in \u001b[0;36mofflineSample_GNN\u001b[0;34m(model, criterion_type, G, u, weighted)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     samples_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu_bool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_weights\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m distances \u001b[38;5;241m=\u001b[39m [[y_pred[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m S] \u001b[38;5;28;01mfor\u001b[39;00m S \u001b[38;5;129;01min\u001b[39;00m sample_sets]\n\u001b[1;32m     25\u001b[0m index \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmin\u001b[39m(d)) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m distances]\n",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(gpu_bool, model, criterion_type, samples_x, samples_edge_index, samples_weights)\u001b[0m\n\u001b[1;32m     33\u001b[0m pred_all \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 35\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Perform a single forward pass.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m criterion_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbce\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mce\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultimargin\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#  Use the class with highest probability.\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/shortestpath/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/shortestpath/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/notebooks/new shortest path/final/Models.py:69\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, edge_index, weights)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m     71\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/envs/shortestpath/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/shortestpath/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/shortestpath/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:222\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    220\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/envs/shortestpath/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:91\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 91\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m     96\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/envs/shortestpath/lib/python3.11/site-packages/torch_geometric/utils/loop.py:370\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    366\u001b[0m     loop_attr[edge_index[\u001b[38;5;241m0\u001b[39m][inv_mask]] \u001b[38;5;241m=\u001b[39m edge_attr[inv_mask]\n\u001b[1;32m    368\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_attr[mask], loop_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 370\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_graphs = 5\n",
    "n = 1000\n",
    "lbd = 1\n",
    "model_dir = 'outputs1'\n",
    "\n",
    "def evaluate_all_algs(model_dir,num_graphs,function,*args,**kwargs):\n",
    "    all_out_channels = [int(item[9:-4]) for item in os.listdir(model_dir) if item.startswith('model_out')]\n",
    "    r = int(np.floor(np.sqrt(n)))\n",
    "    graph_data = generateGraphs(num_graphs,function,*args,**kwargs)\n",
    "    print('Min graph size: '+str(graph_data[3]))\n",
    "    if r not in all_out_channels:\n",
    "        r = max([out for out in all_out_channels if out <= graph_data[3]])\n",
    "    model_outr,_,_,_ = build(r, r, 'gcn','mse','adam','cyclic-cosine')\n",
    "    model_outr.load_state_dict(torch.load('outputs1/model_out'+str(r)+'.pth'))\n",
    "    print('GNN with out_channels = '+str(r))\n",
    "    mse1,dur1 = estimate_AllShortestDistances(graph_data,model_outr,model_outr,'mse',True,True)\n",
    "    if r != 1:\n",
    "        model_out1,_,_,_ = build(1, 1, 'gcn','mse','adam','cyclic-cosine')\n",
    "        model_out1.load_state_dict(torch.load('outputs1/model_out1.pth'))\n",
    "        print('GNN with out_channels = 1')\n",
    "        mse2,dur2 = estimate_AllShortestDistances(graph_data,model_out1,model_out1,'mse',True,True)\n",
    "    return [mse1,mse2],[dur1,dur2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
