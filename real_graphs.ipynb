{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from ShortestPathAlgorithms import seedSets\n",
    "from TestTransferability import revise_random_dists, reviseSeedSets\n",
    "\n",
    "def extract_integers_from_line(line):\n",
    "    # Use regular expression to match exactly two integers in a line\n",
    "    matches = re.findall(r'\\b\\d+\\b', line)\n",
    "    if len(matches) == 2:\n",
    "        return int(matches[0]), int(matches[1])\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def process_text_file(file_path):\n",
    "    extracted_integers = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Extract integers from each line\n",
    "            integer1, integer2 = extract_integers_from_line(line)\n",
    "            if integer1 is not None and integer2 is not None:\n",
    "                # If two integers are extracted, store them\n",
    "                extracted_integers.append((integer1, integer2))\n",
    "    return extracted_integers\n",
    "\n",
    "def get_files_with_substring(directory_path, substring):\n",
    "    file_paths = []\n",
    "    for foldername, subfolders, filenames in os.walk(directory_path):\n",
    "        for filename in filenames:\n",
    "            if substring in filename:\n",
    "                file_paths.append(os.path.join(foldername, filename))\n",
    "    return file_paths\n",
    "\n",
    "def create_graph_from_edges(edge_list):\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "    return G.to_directed()\n",
    "\n",
    "def can_convert_to_undirected(directed_graph):\n",
    "    for edge in directed_graph.edges():\n",
    "        if not directed_graph.has_edge(edge[1], edge[0]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "dir_nums = [1,2,3,4,5,6,7,8,16,17,18,19,20,21,25,27,28,29,30,31]\n",
    "path = '/home/myl/notebooks/shortest-path/version14/samples/real_graphs/'\n",
    "dirs = [path+str(num) for num in dir_nums]\n",
    "\n",
    "dir = os.path.dirname(os.getcwd())+'/samples'\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "sample_dir = dir + '/real_graphs'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "k_max = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graphs = []\n",
    "all_graph_info = []\n",
    "all_random_seeds = []\n",
    "i = 0\n",
    "for dir_path in dirs:\n",
    "    paths1 = get_files_with_substring(dir_path,'txt')\n",
    "    paths2 = get_files_with_substring(dir_path,'csv')\n",
    "    paths = paths1+paths2\n",
    "    paths = [p for p in paths if 'README' not in p and 'descriptions' not in p]\n",
    "    if '25' in dir_path:\n",
    "        paths = paths[:1]\n",
    "    print(paths)\n",
    "    graphs = []\n",
    "    targets = []\n",
    "    for file_path in paths:\n",
    "        extracted_integers = process_text_file(file_path)\n",
    "        G = create_graph_from_edges(extracted_integers)\n",
    "        largest_component = max(nx.strongly_connected_components(G), key=len)\n",
    "        G = G.subgraph(largest_component)\n",
    "        G = nx.relabel_nodes(G, {node: index for index, node in enumerate(G.nodes())})\n",
    "        if len(G.edges()) < 250000:\n",
    "            i += 1\n",
    "            print(i)\n",
    "            print(len(G.nodes()),len(G.edges()),can_convert_to_undirected(G))\n",
    "            graphs.append(G)\n",
    "            graph_info = G, False, False\n",
    "            all_graph_info.append(graph_info)\n",
    "            random_seeds = []\n",
    "            for k in range(k_max):\n",
    "                random_seeds.append(seedSets(graph_info,k+1))\n",
    "            all_random_seeds.append(random_seeds)\n",
    "        else:\n",
    "            print('not selected',len(G.nodes()),len(G.edges()),can_convert_to_undirected(G))\n",
    "    all_graphs.append(graphs)\n",
    "    \n",
    "samples = all_graph_info, all_random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sample_dir+'/all_graphs.pkl'\n",
    "# if os.path.exists(p):\n",
    "#     with open(p, 'rb') as file:\n",
    "#         samples = pickle.load(file)\n",
    "# else:\n",
    "#     raise AssertionError('Data not found.')\n",
    "\n",
    "if len(samples) < 4:\n",
    "    samples = revise_random_dists(samples)\n",
    "if len(samples[2]) != 6:\n",
    "    samples = samples[0],samples[1],[None]*6,samples[2],samples[3]\n",
    "with open(p, 'wb') as file:\n",
    "    pickle.dump(samples, file)\n",
    "# if samples[2][0] == None:\n",
    "#     print('Calculating degree centrality...')\n",
    "#     samples = reviseSeedSets(samples,centralities=['degree'])\n",
    "#     with open(p, 'wb') as file:\n",
    "#         pickle.dump(samples, file)\n",
    "# if samples[2][1] == None:\n",
    "#     print('Calculating closeness centrality...')\n",
    "#     samples = reviseSeedSets(samples,centralities=['closeness'])\n",
    "#     with open(p, 'wb') as file:\n",
    "#         pickle.dump(samples, file)\n",
    "# if samples[2][2] == None:\n",
    "#     print('Calculating betweenness centrality...')\n",
    "#     samples = reviseSeedSets(samples,centralities=['betweenness'])\n",
    "#     with open(p, 'wb') as file:\n",
    "#         pickle.dump(samples, file)\n",
    "# if samples[3][3] == None:\n",
    "#     print('Calculating harmonic centrality...')\n",
    "#     samples = reviseSeedSets(samples,centralities=['harmonic'])\n",
    "#     with open(p, 'wb') as file:\n",
    "#         pickle.dump(samples, file)\n",
    "# if samples[3][4] == None:\n",
    "#     print('Calculating laplacian centrality...')\n",
    "#     samples = reviseSeedSets(samples,centralities=['laplacian'])\n",
    "#     with open(p, 'wb') as file:\n",
    "#         pickle.dump(samples, file)\n",
    "# if samples[2][5] == None:\n",
    "#     print('Calculating pagerank centrality...')\n",
    "#     samples = reviseSeedSets(samples,centralities=['pagerank'])\n",
    "# with open(p, 'wb') as file:\n",
    "#     pickle.dump(samples, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
