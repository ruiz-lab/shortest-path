{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from Graphs import matrix_to_graph, graph_to_matrix, ErdosRenyiGraph, dRegularGraph\n",
    "from Algorithms import shortestDistances_networkx, shortestDistances_GNN, sampleSets, offlineSketch, shortestDistances_Sarma, shortestDistances_Bourgain\n",
    "from Models import build,predict,predict_allBatches,run,run_out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSamples_inner(num_graphs,function,*args,**kwargs):\n",
    "    graphs = []\n",
    "    sampleSets = []\n",
    "    samples_x = []\n",
    "    samples_y = []\n",
    "    samples_edge_index = []\n",
    "    samples_weights = []\n",
    "    k = 0\n",
    "    n_rejected1 = 0\n",
    "    n_rejected2 = 0\n",
    "    while k < num_graphs:\n",
    "        try:\n",
    "            G,directed,weighted = function(*args,**kwargs)\n",
    "            n = len(G.nodes())\n",
    "            r = int(np.floor(np.sqrt(n)))\n",
    "            largest_component = max(nx.strongly_connected_components(G), key=len)\n",
    "            num_nodes = len(largest_component)\n",
    "            if num_nodes >= max(r,10):\n",
    "                G = G.subgraph(largest_component)\n",
    "                G = nx.relabel_nodes(G, {node: index for index, node in enumerate(G.nodes())})\n",
    "                graphs.append((G,directed,weighted))\n",
    "                sampleSets.append(sampleSets(graphs[-1],1),sampleSets(graphs[-1],2),sampleSets(graphs[-1],3),sampleSets(graphs[-1],4))\n",
    "                seeds = np.random.choice(range(num_nodes),size=r,replace=False)\n",
    "                x = np.zeros((num_nodes,r))\n",
    "                y = np.zeros((num_nodes,r))\n",
    "                for i in range(r):\n",
    "                    u = seeds[i]\n",
    "                    x[u,i] = 1\n",
    "                    y[:,i] = shortestDistances_networkx(graphs[-1],source=u) ## edit this line to train another type of model\n",
    "                samples_x.append(torch.tensor(x.astype(np.float32), requires_grad=True))\n",
    "                samples_y.append(torch.tensor(y).to(torch.float32))\n",
    "                samples_edge_index.append(torch.tensor(np.array(list(G.edges())).T).to(torch.int64))\n",
    "                if weighted: \n",
    "                    samples_weights.append(torch.tensor(nx.get_edge_attributes(G,'weight').values()).to(torch.float32))\n",
    "                k += 1\n",
    "            else:\n",
    "                n_rejected2 += 1\n",
    "        except:\n",
    "            n_rejected1 += 1\n",
    "        if n_rejected1 + n_rejected2 >= 10000:\n",
    "            raise ValueError('Possibly stuck in an infinite loop.')\n",
    "    print('Number of graphs rejected because Bourgain\\'s and Sarma\\'s algorithms yield errors: ',n_rejected1)\n",
    "    print('Number of graphs rejected because the largest component has insufficient size: ',n_rejected2)\n",
    "    return graphs,sampleSets,[samples_x,samples_y,samples_edge_index,samples_weights]\n",
    "\n",
    "def generateSamples(n_train,n_val,n_test,function,*args,**kwargs):\n",
    "    print('Generating training data...')\n",
    "    train = generateSamples_inner(n_train,function,*args,**kwargs)\n",
    "    print('Generating validation data...')\n",
    "    val = generateSamples_inner(n_val,function,*args,**kwargs)\n",
    "    print('Generating test data...')\n",
    "    test = generateSamples_inner(n_test,function,*args,**kwargs)\n",
    "    return train, val, test\n",
    "\n",
    "def shortestDistances_Sarma_Bourgain(model,criterion_type,graph_info,sampleSet,actual):\n",
    "    pred = np.zeros((6,4))\n",
    "    mse = np.zeros((6,4))\n",
    "    dur1 = np.zeros((6,4))\n",
    "    dur2 = np.zeros((6,4))\n",
    "    for i in range(len(sampleSet)):\n",
    "        dist,d1,d2 = shortestDistances_Sarma(graph_info,sampleSet[i])\n",
    "        pred[0,i] = dist\n",
    "        mse[0,i] = mean_squared_error(actual, dist)\n",
    "        dur1[0,i] = d1\n",
    "        dur2[0,i] = d2\n",
    "        dist,d1,d2 = shortestDistances_Sarma(graph_info,sampleSet[i],method='GNN',model=model,criterion_type=criterion_type)\n",
    "        pred[1,i] = dist\n",
    "        mse[1,i] = mean_squared_error(actual, dist)\n",
    "        dur1[1,i] = d1\n",
    "        dur2[1,i] = d2\n",
    "        dist,d1,d2 = shortestDistances_Sarma(graph_info,sampleSet[i],method='BFS')\n",
    "        pred[2,i] = dist\n",
    "        mse[2,i] = mean_squared_error(actual, dist)\n",
    "        dur1[2,i] = d1\n",
    "        dur2[2,i] = d2\n",
    "        dist,d1,d2 = shortestDistances_Bourgain(graph_info,sampleSet[i])\n",
    "        pred[3,i] = dist\n",
    "        mse[3,i] = mean_squared_error(actual, dist)\n",
    "        dur1[3,i] = d1\n",
    "        dur2[3,i] = d2\n",
    "        dist,d1,d2 = shortestDistances_Bourgain(graph_info,sampleSet[i],method='GNN',model=model,criterion_type=criterion_type)\n",
    "        pred[4,i] = dist\n",
    "        mse[4,i] = mean_squared_error(actual, dist)\n",
    "        dur1[4,i] = d1\n",
    "        dur2[4,i] = d2\n",
    "        dist,d1,d2 = shortestDistances_Bourgain(graph_info,sampleSet[i],method='BFS')\n",
    "        pred[5,i] = dist\n",
    "        mse[5,i] = mean_squared_error(actual, dist)\n",
    "        dur1[5,i] = d1\n",
    "        dur2[5,i] = d2\n",
    "    return pred,mse,dur1,dur2\n",
    "\n",
    "def evaluate_all_distances(model,criterion_type,graphs,sampleSets,title=None,display_results=False):\n",
    "    \n",
    "    all_actual = []\n",
    "    all_dur_network = []\n",
    "    all_pred_GNN = []\n",
    "    all_mse_GNN = []\n",
    "    all_dur_GNN = []\n",
    "    all_pred = []\n",
    "    all_mse = []\n",
    "    all_dur1 = []\n",
    "    all_dur2 = []\n",
    "    for graph_info,sampleSet in list(zip(graphs,sampleSets)):\n",
    "        actual,dur_network = shortestDistances_networkx(graph_info)\n",
    "        pred_GNN,dur_GNN = shortestDistances_GNN(model,criterion_type,graph_info)\n",
    "        pred,mse,dur1,dur2 = shortestDistances_Sarma_Bourgain(model,criterion_type,graph_info,sampleSet,actual)\n",
    "        all_actual.append(actual)\n",
    "        all_dur_network.append(dur_network)\n",
    "        all_pred_GNN.append(pred_GNN)\n",
    "        all_mse_GNN.append(mean_squared_error(actual, pred_GNN))\n",
    "        all_dur_GNN.append(dur_GNN)\n",
    "        all_pred.append(pred)\n",
    "        all_mse.append(mse)\n",
    "        all_dur1.append(dur1)\n",
    "        all_dur2.append(dur2)\n",
    "    all_dur_network = np.array(all_dur_network)\n",
    "    mean_dur_network = np.mean(all_dur_network,axis=0)\n",
    "    all_mse_GNN = np.array(all_mse_GNN)\n",
    "    mean_mse_GNN = np.mean(all_mse_GNN,axis=0)\n",
    "    all_dur_GNN = np.array(all_dur_GNN)\n",
    "    mean_dur_GNN = np.mean(all_dur_GNN,axis=0)\n",
    "    all_mse = np.array(all_mse)\n",
    "    mean_mse = np.mean(all_mse,axis=0)\n",
    "    all_dur1 = np.array(all_dur1)\n",
    "    mean_dur1 = np.mean(all_dur1,axis=0)\n",
    "    all_dur2 = np.array(all_dur2)\n",
    "    mean_dur2 = np.mean(all_dur2,axis=0)\n",
    "    \n",
    "    if display_results:\n",
    "        pass\n",
    "\n",
    "    return [all_actual,all_pred_GNN,all_pred],[mean_mse_GNN,mean_mse],[mean_dur_network,mean_dur_GNN,mean_dur1,mean_dur2]\n",
    "    \n",
    "def evaluate_random_distances(alpha,model,criterion_type,graphs,sampleSets,title=None,display_results=False):\n",
    "\n",
    "    all_actual = []\n",
    "    all_dur_network = []\n",
    "    all_pred_GNN = []\n",
    "    all_mse_GNN = []\n",
    "    all_dur_GNN = []\n",
    "    all_pred = []\n",
    "    all_mse = []\n",
    "    all_dur1 = []\n",
    "    all_dur2 = []\n",
    "    for graph_info,sampleSet in list(zip(graphs,sampleSets)):\n",
    "        num_nodes = len(graph_info[0].nodes())\n",
    "        num_pairs = (num_nodes*(num_nodes-1)/2)**(1/alpha)\n",
    "        k = 0\n",
    "        nodes = range(num_nodes)\n",
    "        pairs = []\n",
    "        pairs_dump = []\n",
    "        while k <= num_pairs:\n",
    "            pair = tuple(np.random.choice(nodes,size=2,replace=False))\n",
    "            if pair not in pairs:\n",
    "                pairs.append(pair)\n",
    "                pairs_dump.append(pair)\n",
    "                k += 1\n",
    "\n",
    "        if graph_info[1]: # if directed\n",
    "            seeds = list(set(np.array(pairs_dump)[:,0]))\n",
    "            dist = np.zeros((num_nodes,num_seeds))\n",
    "            #for s in seeds:\n",
    "            #actual,dur_network = shortestDistances_networkx(graph_info)\n",
    "\n",
    "            pred_GNN,dur_GNN = shortestDistances_GNN(model,criterion_type,graph_info,seeds=seeds)\n",
    "\n",
    "            pred,mse,dur1,dur2 = shortestDistances_Sarma_Bourgain(model,criterion_type,graph_info,sampleSet,actual)\n",
    "            all_actual.append(actual)\n",
    "            all_dur_network.append(dur_network)\n",
    "            all_pred_GNN.append(pred_GNN)\n",
    "            all_mse_GNN.append(mean_squared_error(actual, pred_GNN))\n",
    "            all_dur_GNN.append(dur_GNN)\n",
    "            all_pred.append(pred)\n",
    "            all_mse.append(mse)\n",
    "            all_dur1.append(dur1)\n",
    "            all_dur2.append(dur2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            seeds = []\n",
    "            while len(pairs_dump) > 0:\n",
    "                flattened = list(chain(*pairs_dump))\n",
    "                most_frequent_item = Counter(flattened).most_common(flattened[-1])\n",
    "                seeds.append(most_frequent_item[0][0] if most_frequent_item else None)\n",
    "                pairs_dump = [p for p in pairs_dump if seeds[-1] not in p]\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_sizes = list(np.array(range(1,10))*10)+list(2**np.array(range(9))*100)\n",
    "for n in graph_sizes:\n",
    "    for lbd in [2,4,6,8]:\n",
    "        train,val,test = generateSamples(200,50,50,dRegularGraph,n,lbd)\n",
    "        graphs_train = train[0]\n",
    "        sampleSets_k1_train = train[1]\n",
    "        sampleSets_k2_train = train[2]\n",
    "        sampleSets_k3_train = train[3]\n",
    "        sampleSets_k4_train = train[4]\n",
    "        graphs_val = val[0]\n",
    "        sampleSets_k1_val = val[1]\n",
    "        sampleSets_k2_val = val[2]\n",
    "        sampleSets_k3_val = val[3]\n",
    "        sampleSets_k4_val = val[4]\n",
    "        graphs_val = test[0]\n",
    "        sampleSets_k1_test = test[1]\n",
    "        sampleSets_k2_test = test[2]\n",
    "        sampleSets_k3_test = test[3]\n",
    "        sampleSets_k4_test = test[4]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
